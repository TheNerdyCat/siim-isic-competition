{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIIM-ISIC - Train\n",
    "\n",
    "##### In this notebook we focus on:\n",
    " 1. Reading in the data\n",
    " - Data manipulation and preparation\n",
    " - Image augmentation\n",
    " - Model architecture creation\n",
    " - Cross Validation strategy creation\n",
    " - Model training\n",
    " - Test-time augmentations (TTAs)\n",
    " - Submission creation\n",
    "\n",
    "##### Ideas I wasn't able to explore:\n",
    "- External data\n",
    "- Focal loss\n",
    "- TFRecords\n",
    "- Having different img size inputs within CV strategy (e.g. fold 0 = 128x128, fold 1 = 256x256)\n",
    "- Pixel normalisation / centering. For some reason this was computationally too expensive, so maybe I didn't do it properly...\n",
    "\n",
    "##### Things I learned:\n",
    " - Setting up the entire pipeline simply from the start. All the way from data reading to submission - a baseline procedure in place at the beginning makes it so much easier to plug and play.\n",
    " - It is so important to track and record all your experiments! And in as much detail as possible!!\n",
    " - Having a development environment style notebook, where if you want to change parameters it is very easy to do and the code doesn't break.\n",
    " - Test time augmentations are critical in both OOF training validation AND test predictions. Under the impression so far that any TTAs you do in generating submission predictions should be the same as in making OOF predictions (although would appreciate being corrected if this is not the case).\n",
    " - Looping through images and individually doing augmentations are more time effective than doing augmentations to an entire batch.\n",
    " - Learning rate schedules are so important - they need to fit in with your own specific model patterns and nuances. There is no one-size-fits all schedule.\n",
    " - Definitely consider model checkpoints, and early stopping continues to be effective (particularly on a second validation set).\n",
    " - Doing slightly different things in each fold (changing augs slightly, for example) can be effective.\n",
    " - Starting training iterations on small image sizes (128x128) while you work out baseline architecture, before increasing to larger images with a more established architecture can save a lot of time. But be careful about memory capability!\n",
    " - If possible, train the same model arhitectures under different seeds and compare CV differences as a way to avoid overfitting. These can even be ensembled at the end.\n",
    " - Batch normalisation and image normalistion are completely different, and some people don't realise this!\n",
    " - The secret to success, is a robust and effective CV strategy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.00 Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#tqdm_notebook().pandas()\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Data prep\n",
    "import pydicom as dicom # to handle dicom files\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Modelling packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tensorflow.keras.layers import Input, Add, Dense, BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')\n",
    "\n",
    "# Data access\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.00 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - mel stands for melanoma\n",
    "input_path = '../input'\n",
    "mel_dir_path = os.path.join(input_path, 'siim-isic-melanoma-classification')\n",
    "\n",
    "train_metadata_path = os.path.join(mel_dir_path, 'train.csv')\n",
    "test_metadata_path = os.path.join(mel_dir_path, 'test.csv')\n",
    "sample_sub_path = os.path.join(mel_dir_path, 'sample_submission.csv')\n",
    "\n",
    "train_img_path = os.path.join(mel_dir_path, 'train')\n",
    "test_img_path = '512x512_jpgs/test'\n",
    "\n",
    "# Read train metadata\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "\n",
    "# Read sample submission\n",
    "sample_sub = pd.read_csv(sample_sub_path)\n",
    "\n",
    "preprocessed_images_path = 'preprocessed_images/'\n",
    "\n",
    "# Remove duplicates\n",
    "duplicates = pd.read_csv('2020_Challenge_duplicates.csv')\n",
    "\n",
    "train_metadata = train_metadata[(~train_metadata['image_name'].isin(duplicates['ISIC_id_paired']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: efficientnet_b5_512x512_seed14\n"
     ]
    }
   ],
   "source": [
    "# Some definitions going forward\n",
    "ROWS = 512 # Default row size\n",
    "COLS = 512 # Default col size\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 4\n",
    "CLASSES = 2\n",
    "\n",
    "# Read all images in and subset in CV? Or Read images inside each fold in CV?\n",
    "read_images_in_fold = True\n",
    "\n",
    "# Uncomment as appropriate\n",
    "\n",
    "#MODEL_TO_USE = 'densenet201'\n",
    "#MODEL_TO_USE = 'inception_resnetv2' \n",
    "#MODEL_TO_USE = 'xception'\n",
    "\n",
    "#MODEL_TO_USE = 'inceptionv3'\n",
    "#MODEL_TO_USE = 'vgg19'\n",
    "\n",
    "MODEL_TO_USE = 'efficientnet_b5'\n",
    "####MODEL_TO_USE = 'resnext101'\n",
    "#MODEL_TO_USE = 'resnet152v2'\n",
    "####MODEL_TO_USE = 'efficientnet_b0'\n",
    "####MODEL_TO_USE = 'efficientnet_b1'\n",
    "####MODEL_TO_USE = 'efficientnet_b2'\n",
    "####MODEL_TO_USE = 'efficientnet_b3'\n",
    "####MODEL_TO_USE = 'efficientnet_b4'\n",
    "####MODEL_TO_USE = 'densenet169'\n",
    "####MODEL_TO_USE = 'densenet121'\n",
    "####MODEL_TO_USE = 'resnet50v2'\n",
    "####MODEL_TO_USE = 'resnet101v2'\n",
    "####MODEL_TO_USE = 'resnext50'\n",
    "\n",
    "\n",
    "# Parameters for each fold\n",
    "# standard_models = [128, 256, 384, 512]\n",
    "# efficient_nets = [224, 240, 260, 300, 380, 456]\n",
    "\n",
    "kfold_params = {\n",
    "    0: {'ROWS':ROWS,'COLS':COLS,'AUG':'fliplr'},\n",
    "    1: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot90' },\n",
    "    2: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot180'},\n",
    "    3: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot270'},\n",
    "    4: {'ROWS':ROWS,'COLS':COLS,'AUG':'fliplr'},\n",
    "    5: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot90' },\n",
    "    6: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot180'},\n",
    "    7: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot270'}\n",
    "\n",
    "}\n",
    "\n",
    "KFOLDS = len(kfold_params)\n",
    "\n",
    "SEED = 14\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model_name_save = MODEL_TO_USE + '_' + str(ROWS) + 'x' + str(COLS) + '_seed' + str(SEED)\n",
    "\n",
    "# Create weights path if does not exist already\n",
    "if not os.path.exists(f'weights/{model_name_save}'):\n",
    "    os.mkdir(f'weights/{model_name_save}')\n",
    "\n",
    "print(f'Model name: {model_name_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_metadata['target']\n",
    "\n",
    "def read_jpgs(filenames, rows, cols, loading_bar=True):\n",
    "\n",
    "    # Read images in\n",
    "    image_list = []\n",
    "    if loading_bar == True:\n",
    "        for image_name in tqdm(filenames):\n",
    "            image_path = os.path.join(preprocessed_images_path, image_name) + '.jpg'\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "            image = cv2.resize(image,(rows,cols))\n",
    "            image_list.append(image)\n",
    "    elif loading_bar == False:\n",
    "        for image_name in filenames:\n",
    "            image_path = os.path.join(preprocessed_images_path, image_name) + '.jpg'\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "            image = cv2.resize(image,(rows,cols))\n",
    "            image_list.append(image)\n",
    "\n",
    "    return(image_list)\n",
    "            \n",
    "            \n",
    "def prepare_images(use_raw_images=False):\n",
    "    if use_raw_images == True:\n",
    "        for del_filename in os.listdir(preprocessed_images_path):\n",
    "            del_file_path = os.path.join(preprocessed_images_path, del_filename)\n",
    "            try:\n",
    "                if os.path.isfile(del_file_path) or os.path.islink(del_file_path):\n",
    "                    os.unlink(del_file_path)\n",
    "                elif os.path.isdir(del_file_path):\n",
    "                    shutil.rmtree(del_file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (del_file_path, e))\n",
    "        # Read images in\n",
    "        image_list = []\n",
    "        filenames = train_metadata['image_name']\n",
    "\n",
    "        for image_name in tqdm(filenames):\n",
    "            image_path = os.path.join(train_img_path, image_name) + '.dcm'\n",
    "            # Read the dcm image in\n",
    "            image = dicom.dcmread(image_path).pixel_array\n",
    "\n",
    "            res = cv2.resize(image,(ROWS,COLS))\n",
    "            image_list.append(res)\n",
    "            # Save processed image\n",
    "            new_filename = preprocessed_images_path + image_name + '.jpg'\n",
    "            cv2.imwrite(new_filename, res)\n",
    "\n",
    "    elif use_raw_images == False:\n",
    "        image_list = read_jpgs(filenames=train_metadata['image_name'])\n",
    "    return image_list\n",
    "\n",
    "if read_images_in_fold == False:\n",
    "    X_train_img = np.array(prepare_images())\n",
    "    print(f'X_train_img shape: {X_train_img.shape}')\n",
    "\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.00 Data Preprocessing\n",
    " \n",
    "### 3.01 Train Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>anatom_site_general_challenge_head/neck</th>\n",
       "      <th>anatom_site_general_challenge_lower_extremity</th>\n",
       "      <th>anatom_site_general_challenge_oral/genital</th>\n",
       "      <th>anatom_site_general_challenge_palms/soles</th>\n",
       "      <th>anatom_site_general_challenge_torso</th>\n",
       "      <th>anatom_site_general_challenge_upper_extremity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id  age_approx  target  sex_female  sex_male  \\\n",
       "0  ISIC_2637011  IP_7279968        45.0       0           0         1   \n",
       "1  ISIC_0015719  IP_3075186        45.0       0           1         0   \n",
       "2  ISIC_0052212  IP_2842074        50.0       0           1         0   \n",
       "3  ISIC_0068279  IP_6890425        45.0       0           1         0   \n",
       "4  ISIC_0074268  IP_8723313        55.0       0           1         0   \n",
       "\n",
       "   anatom_site_general_challenge_head/neck  \\\n",
       "0                                        1   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   anatom_site_general_challenge_lower_extremity  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              1   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   anatom_site_general_challenge_oral/genital  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   anatom_site_general_challenge_palms/soles  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   anatom_site_general_challenge_torso  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   anatom_site_general_challenge_upper_extremity  \n",
       "0                                              0  \n",
       "1                                              1  \n",
       "2                                              0  \n",
       "3                                              0  \n",
       "4                                              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove diagnosis as too many 'unknown' values\n",
    "# Remove benign_malignant as the same as target variable\n",
    "train_df = train_metadata.drop(['diagnosis','benign_malignant'], axis=1)\n",
    "\n",
    "# Replace whitespace in anatom_site_general_challenge with underscore\n",
    "train_df['anatom_site_general_challenge'] = train_df[\n",
    "    'anatom_site_general_challenge'].replace(' ', '_', regex=True)\n",
    "\n",
    "# Encode sex feature\n",
    "train_df = train_df.merge(pd.get_dummies(train_df[\n",
    "    ['sex','anatom_site_general_challenge']]), left_index=True, right_index=True)\n",
    "\n",
    "train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
    "\n",
    "train_df.drop(['sex', 'anatom_site_general_challenge'], axis=1, inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = np.asarray(train_df.drop(['patient_id', 'target'], axis=1))\n",
    "\n",
    "y_train = np.asarray(train_df['target'])\n",
    "groups = list(train_df['patient_id'])\n",
    "\n",
    "del [train_metadata, train_df, duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.02 Train Images\n",
    "Standardise images by subtracting the per-channel mean for the training dataset and dividing by the per-channel standard deviation for the whole training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imgs(train_imgs, test_imgs):\n",
    "    \"\"\"\n",
    "    Centers images by minusing the mean and dividing by std\n",
    "    \n",
    "    *train_imgs: (array) train images to read in and normalise\n",
    "    *test_imgs: (array) test images to read in and normalise\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Preprocessing images...\\n')\n",
    "    # Convert pixel values to float\n",
    "    train_imgs = train_imgs.astype(float)\n",
    "    test_imgs = test_imgs.astype(float)\n",
    "\n",
    "    # Get per-channel means and stds    \n",
    "    train_means = train_imgs.reshape(-1, train_imgs.shape[-1]).mean(axis=0)\n",
    "    train_stds = train_imgs.reshape(-1, train_imgs.shape[-1]).std(axis=0)\n",
    "\n",
    "    # Standardise images\n",
    "    train_imgs -= train_means\n",
    "    train_imgs /= train_stds\n",
    "    \n",
    "    test_imgs -= train_means\n",
    "    test_imgs /= train_stds\n",
    "        \n",
    "    #print(f'Train per-channel means: {train_imgs.reshape(-1, train_imgs.shape[-1]).mean(axis=0)}')\n",
    "    #print(f'Trin per-channel stds: {train_imgs.reshape(-1, train_imgs.shape[-1]).std(axis=0)}')\n",
    "\n",
    "    return(train_imgs, test_imgs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.00 Train Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation pipelines\n",
    "\n",
    "def make_train_augmentations(X_img, X_met, y, p, aug):\n",
    "    \"\"\"\n",
    "    Make a random subset of p proportion. Apply augmentations\n",
    "    to the subset and append back to the original dataset, \n",
    "    making necessary changes to labels.\n",
    "    \n",
    "    *X_img: (array) Train images to read in and augment\n",
    "    *X_met: (array) Train metadata to copy as per augmentated images\n",
    "    *y: (array) Train labels to copy as per augmented images\n",
    "    *p: (float) sample size probability\n",
    "    *aug: (string) ['fliplr', 'rot90', 'rot180', 'rot270']\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Augmenting images...')\n",
    "    # Get a sample of X and y based on p proportion\n",
    "    sample_size = int(round(len(y) * p))\n",
    "    idx_sample = random.sample(range(0, len(y), 1), sample_size)\n",
    "\n",
    "    # Make augmentations to sample\n",
    "    if aug == 'fliplr':\n",
    "        X_img = np.concatenate((X_img,\n",
    "                                np.array([np.fliplr(X_img[i]) for i in idx_sample])),\n",
    "                               axis=0)\n",
    "    elif aug == 'rot90':\n",
    "        X_img = np.concatenate((X_img,\n",
    "                                np.array([np.rot90(X_img[i], 1) for i in idx_sample])),\n",
    "                               axis=0)\n",
    "    elif aug == 'rot180':\n",
    "        X_img = np.concatenate((X_img,\n",
    "                                np.array([np.rot90(X_img[i], 2) for i in idx_sample])),\n",
    "                               axis=0)\n",
    "    elif aug == 'rot270':\n",
    "        X_img = np.concatenate((X_img,\n",
    "                                np.array([np.rot90(X_img[i], 3) for i in idx_sample])),\n",
    "                               axis=0)\n",
    "    \n",
    "    # Copy metadata accordingly\n",
    "    X_met_sample = np.array([X_met[i] for i in idx_sample])\n",
    "    X_met = np.concatenate((X_met, X_met_sample), axis=0)\n",
    "    del X_met_sample\n",
    "    \n",
    "    # Copy labels accordingly\n",
    "    y_sample = np.array([y[i] for i in idx_sample])\n",
    "    y = np.concatenate((y, y_sample), axis=0)\n",
    "    del y_sample\n",
    "\n",
    "    #X_img, X_met, y = shuffle(X_img, X_met, y, random_state=SEED)\n",
    "\n",
    "    return(X_img, X_met, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (32701, 10)\n",
      "Train targets shape: (32701,)\n"
     ]
    }
   ],
   "source": [
    "if read_images_in_fold == False:\n",
    "    print(f'Train imgs shape: {X_train_img.shape}')\n",
    "print(f'Train dataframe shape: {X_train_df.shape}')\n",
    "print(f'Train targets shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.00 Modelling\n",
    "### 5.01 Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.51\n",
      "Weight for class 1: 28.14\n"
     ]
    }
   ],
   "source": [
    "# Due to the high data imbalance, we add extra weight to the target class\n",
    "neg, pos = np.bincount(y_train)\n",
    "\n",
    "weight_for_0 = (1 / neg)*(len(y_train)) / 2.0 \n",
    "weight_for_1 = (1 / pos)*(len(y_train)) / 2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.02 Learning Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_lrfn(lr_start          = 0.000005,\n",
    "               lr_max            = 0.000020 * strategy.num_replicas_in_sync,\n",
    "               lr_min            = 0.000001, \n",
    "               lr_rampup_epochs  = 4,  \n",
    "               lr_sustain_epochs = 0, \n",
    "               lr_decay          = 0.8): \n",
    "    \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn\n",
    "\n",
    "lrfn = build_lrfn()\n",
    "\n",
    "plt.plot([lrfn(epoch) for epoch in range(EPOCHS)])\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.03 Compiler Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to observe while training\n",
    "METRICS = [keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.04 Metdata Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we'll feed the metadata into before concatenation\n",
    "model_metadata = keras.Sequential()\n",
    "\n",
    "if read_images_in_fold == True:\n",
    "    model_metadata.add(keras.layers.Dense(256, activation='relu', input_shape=(X_train_df.shape[1] - 1,)))\n",
    "elif read_images_in_fold == False:\n",
    "    model_metadata.add(keras.layers.Dense(256, activation='relu', input_shape=(X_train_df.shape[1],)))\n",
    "    \n",
    "model_metadata.add(keras.layers.BatchNormalization())\n",
    "model_metadata.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model_metadata.add(keras.layers.Dense(256, activation='relu'))\n",
    "model_metadata.add(keras.layers.BatchNormalization())\n",
    "model_metadata.add(keras.layers.Dropout(0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.05 CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we'll feed the images into before concatenation\n",
    "def get_cnn_model(kfold, model_to_use=MODEL_TO_USE, verbose=1):\n",
    "    \"\"\"\n",
    "    Returns the model object and the name of the final layer in the model.\n",
    "    \n",
    "    *kfold: (int) fold that the CV is currently on (to determine img size)\n",
    "    *model_to_use: (string) model to retrieve\n",
    "    *verbose: ([0,1]) level of output communication. 0=None, 1=All.\n",
    "    \"\"\"\n",
    "    if verbose == 1:\n",
    "        print('\\nLoading pretrained model...')\n",
    "    \n",
    "    densenet121_weights        = 'pretrained/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    densenet169_weights        = 'pretrained/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    densenet201_weights        = 'pretrained/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    efficientnet_b0_weights    = 'pretrained/efficientnet-b0_imagenet_1000_notop.h5'\n",
    "    efficientnet_b1_weights    = 'pretrained/efficientnet-b1_imagenet_1000_notop.h5'\n",
    "    efficientnet_b2_weights    = 'pretrained/efficientnet-b2_imagenet_1000_notop.h5'\n",
    "    efficientnet_b3_weights    = 'pretrained/efficientnet-b3_imagenet_1000_notop.h5'\n",
    "    efficientnet_b4_weights    = 'pretrained/efficientnet-b4_imagenet_1000_notop.h5'\n",
    "    efficientnet_b5_weights    = 'pretrained/efficientnet-b5_imagenet_1000_notop.h5'\n",
    "    inception_resnetv2_weights = 'pretrained/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    inceptionv3_weights        = 'pretrained/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    resnet50v2_weights         = 'pretrained/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    resnet101v2_weights        = 'pretrained/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    resnet152v2_weights        = 'pretrained/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    resnext50_weights          = 'pretrained/resnext50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    resnext101_weights         = 'pretrained/resnext101_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    vgg19_weights              = 'pretrained/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    xception_weights           = 'pretrained/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "                    \n",
    "    input_shape = (\n",
    "        kfold_params[kfold]['ROWS'],\n",
    "        kfold_params[kfold]['COLS'],\n",
    "        CHANNELS\n",
    "    )\n",
    "    \n",
    "    # DenseNet121\n",
    "    if model_to_use == 'densenet121':\n",
    "        from tensorflow.keras.applications import DenseNet121\n",
    "        model_return = DenseNet121(include_top=False, weights=densenet121_weights,\n",
    "                                  input_shape=input_shape)\n",
    "        \n",
    "    # DenseNet169\n",
    "    elif model_to_use == 'densenet169':\n",
    "        from tensorflow.keras.applications import DenseNet169\n",
    "        model_return = DenseNet169(include_top=False, weights=densenet169_weights,\n",
    "                                  input_shape=input_shape)\n",
    "        \n",
    "    # DenseNet201\n",
    "    elif model_to_use == 'densenet201':\n",
    "        from tensorflow.keras.applications import DenseNet201\n",
    "        model_return = DenseNet201(include_top=False, weights=densenet201_weights,\n",
    "                                  input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B0\n",
    "    elif model_to_use == 'efficientnet_b0':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB0(include_top=False, weights=efficientnet_b0_weights,\n",
    "                                         input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B1\n",
    "    elif model_to_use == 'efficientnet_b1':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB1(include_top=False, weights=efficientnet_b1_weights,\n",
    "                                         input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B2\n",
    "    elif model_to_use == 'efficientnet_b2':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB2(include_top=False, weights=efficientnet_b2_weights,\n",
    "                                         input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B3\n",
    "    elif model_to_use == 'efficientnet_b3':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB3(include_top=False, weights=efficientnet_b3_weights,\n",
    "                                         input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B4\n",
    "    elif model_to_use == 'efficientnet_b4':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB4(include_top=False, weights=efficientnet_b4_weights,\n",
    "                                         input_shape=input_shape)\n",
    "            \n",
    "    # EfficientNet_B5\n",
    "    elif model_to_use == 'efficientnet_b5':\n",
    "        import efficientnet.tfkeras as efficientnet\n",
    "        model_return = efficientnet.EfficientNetB5(include_top=False, weights=efficientnet_b5_weights,\n",
    "                                         input_shape=input_shape)\n",
    "\n",
    "    # InceptionResNetV2\n",
    "    elif model_to_use == 'inception_resnetv2':\n",
    "        from tensorflow.keras.applications import InceptionResNetV2\n",
    "        model_return = InceptionResNetV2(include_top=False, weights=inception_resnetv2_weights,\n",
    "                                               input_shape=input_shape)\n",
    "\n",
    "    # InceptionV3\n",
    "    elif model_to_use == 'inceptionv3':\n",
    "        from tensorflow.keras.applications import InceptionV3\n",
    "        model_return = InceptionV3(include_top=False, weights=inceptionv3_weights,\n",
    "                                  input_shape=input_shape)\n",
    "    \n",
    "    # ResNet50V2\n",
    "    elif model_to_use == 'resnet50v2':\n",
    "        from tensorflow.keras.applications import ResNet50V2\n",
    "        model_return = ResNet50V2(include_top=False, weights=resnet50v2_weights,\n",
    "                                input_shape=input_shape)\n",
    "\n",
    "    # ResNet101V2\n",
    "    elif model_to_use == 'resnet101v2':\n",
    "        from tensorflow.keras.applications import ResNet101V2\n",
    "        model_return = ResNet101V2(include_top=False, weights=resnet101v2_weights,\n",
    "                                  input_shape=input_shape)\n",
    "\n",
    "    # ResNet152V2\n",
    "    elif model_to_use == 'resnet152v2':\n",
    "        from tensorflow.keras.applications import ResNet152V2\n",
    "        model_return = ResNet152V2(include_top=False, weights=resnet152v2_weights,\n",
    "                                  input_shape=input_shape)\n",
    "\n",
    "    # ResNeXt50\n",
    "    elif model_to_use == 'resnext50':\n",
    "        from keras_applications.resnext import ResNeXt50\n",
    "        model_return = ResNeXt50(include_top=False, weights=resnext50_weights,\n",
    "                              input_shape=input_shape,\n",
    "                              backend=keras.backend, \n",
    "                              layers=keras.layers, \n",
    "                              models=keras.models, \n",
    "                              utils=keras.utils)\n",
    "\n",
    "    # ResNeXt101\n",
    "    elif model_to_use == 'resnext101':\n",
    "        from keras_applications.resnext import ResNeXt101\n",
    "        model_return = ResNeXt101(include_top=False, weights=resnext101_weights,\n",
    "                                input_shape=input_shape,\n",
    "                                backend=keras.backend, \n",
    "                                layers=keras.layers, \n",
    "                                models=keras.models, \n",
    "                                utils=keras.utils)\n",
    "        \n",
    "    # VGG19\n",
    "    elif model_to_use == 'vgg19':\n",
    "        from tensorflow.keras.applications import VGG19\n",
    "        model_return = VGG19(include_top=False, weights=vgg19_weights,\n",
    "                      input_shape=input_shape)\n",
    "\n",
    "    # Xception\n",
    "    elif model_to_use == 'xception':\n",
    "        from tensorflow.keras.applications import Xception\n",
    "        model_return = Xception(include_top=False, weights=xception_weights,\n",
    "                                  input_shape=input_shape)\n",
    "        \n",
    "    return(model_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.06 Concatenating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_model(model_cnn, model_metadata, verbose=1):\n",
    "    \"\"\"\n",
    "    Concatenate multiple models, add hidden layers after concatenation\n",
    "    and return complete concatenated model\n",
    "    \n",
    "    *model_cnn: the loaded cnn model object to input \n",
    "    *model_metadata: the loaded metadata model object to input\n",
    "    *verbose: ([0,1]) level of output communication. 0=None, 1=All.\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('Creating complete model...\\n')\n",
    "    # Pretrained cnn model with GlobalAveragePooling\n",
    "    model_cnn_base = keras.Sequential([\n",
    "        Model(model_cnn.input, model_cnn.output),\n",
    "        keras.layers.GlobalAveragePooling2D()\n",
    "    ])\n",
    "    \n",
    "    # Concatenate CNN model with metadata model\n",
    "    model_concat = concatenate([model_cnn_base.output, model_metadata.output], axis=1)\n",
    "    \n",
    "    # Output layer\n",
    "    model_concat = keras.layers.Dense(1, activation='sigmoid', name='final_output')(model_concat)\n",
    "    model_complete = Model(inputs=[model_cnn_base.input, model_metadata.input], outputs=model_concat)\n",
    "    return model_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.07 Stratified Group Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=SEED):\n",
    "    \"\"\" https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation \"\"\"\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, \n",
    "                                   key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.08 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_fold_data(kfold, tdx, vdx, read_images_in_fold=read_images_in_fold, loading_bar=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    *kfold: (int) the current fold in CV\n",
    "    *tdx: (list of ints) train indices for the current fold\n",
    "    *vdx: (list of ints) validation indices for the current fold\n",
    "    *read_images_in_fold: (bool) whether to read the images inside or outside of folds\n",
    "    *loading_bar: (bool) include a loading bar when loading CV images\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Fetching data...')\n",
    "    \n",
    "    # Get values for metadata\n",
    "    X_met, X_met_val, = X_train_df[tdx], X_train_df[vdx]\n",
    "    # Get values for target\n",
    "    y, y_val = y_train[tdx], y_train[vdx]        \n",
    "    \n",
    "    if read_images_in_fold == False:\n",
    "        # Extract images from full image array\n",
    "        X_met, X_met_val = X_met[:, 1:], X_met_val[:, 1:] # Remove name col\n",
    "        X_met, X_met_val = X_met.astype(np.uint8), X_met_val.astype(np.uint8) # Change np type - must be uint8\n",
    "        \n",
    "        # Get values for imgs\n",
    "        X_img = cv2.resize(X_train_img[tdx],\n",
    "                                      (kfold_params[kfold]['ROWS'],  # Row size for current fold\n",
    "                                       kfold_params[kfold]['COLS'])) # Col size for current fold\n",
    "        X_img_val = cv2.resize(X_train_img[vdx], \n",
    "                               (kfold_params[kfold]['ROWS'],  # Row size for current fold\n",
    "                                kfold_params[kfold]['COLS'])) # Col size for current fold\n",
    "            \n",
    "    elif read_images_in_fold == True:\n",
    "        # Read images in from scratch\n",
    "        X_img = np.array(read_jpgs(X_met[:,0], # Img names\n",
    "                                   rows=kfold_params[kfold]['ROWS'], # Row size for current fold\n",
    "                                   cols=kfold_params[kfold]['COLS'], # Col size for current fold\n",
    "                                   loading_bar=loading_bar))\n",
    "        \n",
    "        X_img_val = np.array(read_jpgs(X_met_val[:,0], # Img names\n",
    "                                       rows=kfold_params[kfold]['ROWS'], # Row size for current fold\n",
    "                                       cols=kfold_params[kfold]['COLS'], # Col size for current fold\n",
    "                                       loading_bar=loading_bar))\n",
    "        \n",
    "        X_met, X_met_val = X_met[:, 1:], X_met_val[:, 1:] # Remove name col\n",
    "        X_met, X_met_val = X_met.astype(np.uint8), X_met_val.astype(np.uint8)\n",
    "\n",
    "        \n",
    "    return X_img, X_img_val, X_met, X_met_val, y, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_augmentations(img):\n",
    "    \"\"\"\n",
    "    Returns augmented image(s) and original.\n",
    "    \"\"\"\n",
    "    img_augs = np.concatenate((#np.expand_dims(img, axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 1), axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 2), axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 3), axis=0),\n",
    "                               np.expand_dims(np.fliplr(img), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 1)), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 2)), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 3)), axis=0)),\n",
    "                              axis=0)\n",
    "        \n",
    "    return(img_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model_to_use=MODEL_TO_USE):\n",
    "\n",
    "    k.clear_session()\n",
    "\n",
    "    skf = stratified_group_k_fold(X=X_train_df, y=y_train, groups=groups, k=KFOLDS, seed=SEED)\n",
    "    rocauc_scores = []\n",
    "\n",
    "    print(f'TRAINING {model_to_use.upper()} ON ' + str(KFOLDS) + ' FOLDS\\n')\n",
    "    for fold, (tdx, vdx) in enumerate(skf):\n",
    "        print(f'Fold : {fold}')\n",
    "        print('Img size: ' + str(kfold_params[fold]['ROWS']) + 'x' + str(kfold_params[fold]['ROWS']))\n",
    "        print('Augmentation: ' + str(kfold_params[fold]['AUG']))\n",
    "        print(f'Training on {len(tdx)} samples.')\n",
    "        print(f'Validating on {len(vdx)} samples.')\n",
    "\n",
    "        # Load pretrained model & create name to save weights by\n",
    "        model_cnn = get_cnn_model(kfold=fold, model_to_use=MODEL_TO_USE)\n",
    "        model_save_name = 'weights/' + model_name_save + '/' + model_name_save + '_' + str(fold) + '.h5'\n",
    "\n",
    "        # Fetch in-fold data\n",
    "        X_img, X_img_val, X_met, X_met_val, y, y_val = get_in_fold_data(kfold=fold, tdx=tdx, vdx=vdx)\n",
    "\n",
    "        # Image Preprocessing\n",
    "        #X_img, X_img_val = preprocess_imgs(train_imgs=X_img, test_imgs=X_img_val)\n",
    "\n",
    "        # Image augmentations\n",
    "        X_img, X_met, y = make_train_augmentations(X_img=X_img, \n",
    "                                                   X_met=X_met, \n",
    "                                                   y=y, \n",
    "                                                   p=0.4, \n",
    "                                                   aug=kfold_params[fold]['AUG'])\n",
    "\n",
    "\n",
    "        # CONCATENATED MODEL - Edit below\n",
    "        model = get_complete_model(model_cnn=model_cnn, \n",
    "                                   model_metadata=model_metadata)\n",
    "\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "        # Define learning rate schedule\n",
    "        lr = LearningRateScheduler(lrfn, verbose=True)\n",
    "        # Define early stopping parameters\n",
    "        es = EarlyStopping(monitor='val_auc', \n",
    "                           mode='max',\n",
    "                           restore_best_weights=True, \n",
    "                           verbose=1, \n",
    "                           patience=3)\n",
    "        # Define model checkpoint parameters\n",
    "        mc = ModelCheckpoint(filepath=model_save_name, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True,\n",
    "                             monitor='val_auc', \n",
    "                             mode='max', \n",
    "                             verbose=0)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit([X_img, X_met], y,\n",
    "                  epochs=EPOCHS,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  callbacks = [es, lr, mc],\n",
    "                  class_weight=class_weight,\n",
    "                  verbose=1,\n",
    "                  validation_split=0.25)  \n",
    "        \n",
    "        del [X_img, X_met, y]\n",
    "\n",
    "        # TTAs and validation predictions\n",
    "        print('\\nMaking val predictions')\n",
    "        preds = []\n",
    "        for val_idx in range(len(X_img_val)):\n",
    "            # Add augmented images to each img in X_img_val\n",
    "            X_img_val_augs = np.concatenate((np.expand_dims(X_img_val[val_idx], axis=0),\n",
    "                                        make_test_augmentations(X_img_val[val_idx])))\n",
    "            # Add copies of each corresponding X_met_val for the augmented imgs\n",
    "            X_met_val_augs = np.array([X_met_val[val_idx]] * len(X_img_val_augs))\n",
    "            \n",
    "            # Make prediction for each record\n",
    "            pred = model.predict([X_img_val_augs, X_met_val_augs])\n",
    "            pred = np.mean(pred, axis=0)\n",
    "            preds.append(pred)\n",
    "            \n",
    "        # Calculate OOF ROCAUC following TTAs\n",
    "        oof_rocauc = metrics.roc_auc_score(y_val, preds)\n",
    "\n",
    "        print('')\n",
    "        print('\\nFold ' + str(fold) + ' ROCAUC: ' + str(oof_rocauc))\n",
    "        print('')\n",
    "        rocauc_scores.append(oof_rocauc)\n",
    "        \n",
    "        # Clean up\n",
    "        del [X_img_val, X_met_val, y_val, pred, tdx, vdx, model, oof_rocauc]\n",
    "        gc.collect()\n",
    "\n",
    "    print('\\n\\n############################')\n",
    "    print('Mean OOF ROCAUC: '+ str(np.mean(rocauc_scores))+' ('+str(round(np.std(rocauc_scores), 5))+')')    \n",
    "    print('############################\\n\\n')\n",
    "    return(rocauc_scores)\n",
    "\n",
    "rocauc_scores = train_model(model_to_use=MODEL_TO_USE)\n",
    "\n",
    "# Save the fold results\n",
    "rocauc_scores = pd.DataFrame({'rocauc':rocauc_scores})\n",
    "rocauc_scores_name = f'scores/{model_name_save}_scores.csv'\n",
    "rocauc_scores.to_csv(rocauc_scores_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'--------------\\nFOLD SCORES\\n--------------\\n{rocauc_scores}')\n",
    "print(f'\\n--------------\\nFOLD STATS\\n--------------\\n{rocauc_scores.describe()}')\n",
    "\n",
    "plt.plot(rocauc_scores.index, rocauc_scores, marker='.')\n",
    "plt.title('ROCAUC Fold Results')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('ROCAUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.00 Testing \n",
    "### 6.01 Test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ISIC_0052060', 70.0, 0, ..., 0, 0, 0],\n",
       "       ['ISIC_0052349', 40.0, 0, ..., 0, 0, 0],\n",
       "       ['ISIC_0058510', 55.0, 1, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       ['ISIC_9997917', 25.0, 0, ..., 0, 0, 1],\n",
       "       ['ISIC_9998234', 65.0, 0, ..., 0, 0, 0],\n",
       "       ['ISIC_9999302', 30.0, 0, ..., 0, 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up memory\n",
    "try:\n",
    "    del [X_train_img, X_train_df, y_train]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "test_df = pd.read_csv(test_metadata_path)\n",
    "duplicates = pd.read_csv('2020_Challenge_duplicates.csv')\n",
    "\n",
    "# Replace whitespace in anatom_site_general_challenge with underscore\n",
    "test_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].replace(' ', '_', regex=True)\n",
    "\n",
    "# Encode sex feature\n",
    "test_df = test_df.merge(pd.get_dummies(test_df[['sex','anatom_site_general_challenge']]), \n",
    "                        left_index=True, right_index=True)\n",
    "test_df.drop(['patient_id','sex', 'anatom_site_general_challenge'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "test_df[(~test_df['image_name'].isin(duplicates['ISIC_id_paired']))]\n",
    "\n",
    "test_df = np.asarray(test_df)\n",
    "\n",
    "del duplicates\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.02 Test CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model(kfolds, model_to_use=MODEL_TO_USE):\n",
    "    \"\"\"\n",
    "    *kfolds: list object of applicable folds. (Not an int)\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    for fold in tqdm(range(kfolds)):\n",
    "        model_cnn = get_cnn_model(kfold=fold, model_to_use=MODEL_TO_USE, verbose=0)\n",
    "        \n",
    "        model = get_complete_model(model_cnn=model_cnn, \n",
    "                                   model_metadata=model_metadata,\n",
    "                                   verbose=0)\n",
    "\n",
    "        model.load_weights('../output/weights/' + model_name_save + '/' + model_name_save + '_' + str(fold) + '.h5')\n",
    "        models.append(model)\n",
    "    return(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.03 Test Augmention Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_augmentations(img):\n",
    "    \"\"\"\n",
    "    Returns augmented image(s) and original.\n",
    "    \"\"\"\n",
    "    img_augs = np.concatenate((np.expand_dims(img, axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 1), axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 2), axis=0),\n",
    "                               np.expand_dims(np.rot90(img, 3), axis=0),\n",
    "                               np.expand_dims(np.fliplr(img), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 1)), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 2)), axis=0),\n",
    "                               np.expand_dims(np.fliplr(np.rot90(img, 3)), axis=0)),\n",
    "                              axis=0)\n",
    "        \n",
    "    return(img_augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.04 Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(test_df):\n",
    "    \n",
    "    # Read images in and predict\n",
    "    preds_test = [] # We'll store the final prediction for each image here\n",
    "    \n",
    "    # Convert pixel values to float\n",
    "    #print('Preparing image standardiser...')\n",
    "    #train_imgs = train_imgs.astype(float)\n",
    "    # Get per-channel means and stds\n",
    "    #train_means = train_imgs.reshape(-1, train_imgs.shape[-1]).mean(axis=0)\n",
    "    #train_stds = train_imgs.reshape(-1, train_imgs.shape[-1]).std(axis=0)\n",
    "    \n",
    "    print('Getting models...')\n",
    "    time.sleep(2)\n",
    "    # Retrieve model to use - as per fold image sizes\n",
    "    models = import_model(kfolds=KFOLDS, model_to_use=MODEL_TO_USE)\n",
    "    \n",
    "    print('Generating predictions...')\n",
    "    time.sleep(2)\n",
    "    # Loop through all the test images\n",
    "    for image_row in tqdm(test_df):\n",
    "        # Get image data from dicom file\n",
    "        image_path = os.path.join(test_img_path, image_row[0]) + '.jpg'\n",
    "        # Read the dcm image in\n",
    "        image = cv2.imread(image_path)     \n",
    "\n",
    "        # Drop image name from metadata\n",
    "        image_row = np.delete(image_row, 0).astype(np.uint8)\n",
    "        image_row = np.expand_dims(image_row, axis=0)\n",
    "        \n",
    "        # AUGMENTATIONS\n",
    "        images_all = make_test_augmentations(image)\n",
    "        \n",
    "        pred_proba_list = []        \n",
    "        for image in images_all:\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            pred_proba = np.mean([model.predict([image, image_row]) for model in models], axis=0)\n",
    "            pred_proba_list.append(pred_proba)\n",
    "        \n",
    "        pred_proba = np.mean(pred_proba_list, axis=0)\n",
    "        preds_test.append(pred_proba.tolist()[0][0])\n",
    "        \n",
    "    # Create submission df\n",
    "    submission = pd.DataFrame({sample_sub.columns[0]:test_df[:,1],\n",
    "                           sample_sub.columns[1]:preds_test})\n",
    "   \n",
    "    return(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [01:17<00:00, 10.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 136/10982 [10:53<13:59:19,  4.64s/it]WARNING: Logging before flag parsing goes to stderr.\n",
      "E0817 17:34:14.958288 139882653075264 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = make_submission(test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = f'submissions/{model_name_save}_submission.csv'\n",
    "submission.to_csv(submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some definitions going forward\n",
    "ROWS = 512 # Default row size\n",
    "COLS = 512 # Default col size\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 8\n",
    "CLASSES = 2\n",
    "\n",
    "# Read all images in and subset in CV, or Read images inside each fold in CV\n",
    "read_images_in_fold = True\n",
    "\n",
    "# -- Models ran -- \n",
    "#MODEL_TO_USE = 'densenet201'\n",
    "#MODEL_TO_USE = 'inception_resnetv2' \n",
    "#MODEL_TO_USE = 'xception'\n",
    "#MODEL_TO_USE = 'inceptionv3'\n",
    "\n",
    "# -- Submissions generated -- \n",
    "MODEL_TO_USE = 'vgg19'\n",
    "\n",
    "# -- Staged for running --\n",
    "#MODEL_TO_USE = 'efficientnet_b5'\n",
    "####MODEL_TO_USE = 'resnext101'\n",
    "#MODEL_TO_USE = 'resnet152v2'\n",
    "####MODEL_TO_USE = 'efficientnet_b0'\n",
    "####MODEL_TO_USE = 'efficientnet_b1'\n",
    "####MODEL_TO_USE = 'efficientnet_b2'\n",
    "####MODEL_TO_USE = 'efficientnet_b3'\n",
    "####MODEL_TO_USE = 'efficientnet_b4'\n",
    "####MODEL_TO_USE = 'densenet169'\n",
    "####MODEL_TO_USE = 'densenet121'\n",
    "####MODEL_TO_USE = 'resnet50v2'\n",
    "####MODEL_TO_USE = 'resnet101v2'\n",
    "####MODEL_TO_USE = 'resnext50'\n",
    "\n",
    "\n",
    "# Parameters for each fold\n",
    "# standard_models = [128, 256, 384, 512]\n",
    "# efficient_nets = [224, 240, 260, 300, 380, 456]\n",
    "\n",
    "kfold_params = {\n",
    "    0: {'ROWS':ROWS,'COLS':COLS,'AUG':'fliplr'},\n",
    "    1: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot90' },\n",
    "    2: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot180'},\n",
    "    3: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot270'},\n",
    "    4: {'ROWS':ROWS,'COLS':COLS,'AUG':'fliplr'},\n",
    "    5: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot90' },\n",
    "    6: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot180'},\n",
    "    7: {'ROWS':ROWS,'COLS':COLS,'AUG':'rot270'}\n",
    "\n",
    "}\n",
    "\n",
    "KFOLDS = len(kfold_params)\n",
    "\n",
    "SEED = 14\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model_name_save = MODEL_TO_USE + '_' + str(ROWS) + 'x' + str(COLS) + '_seed' + str(SEED)\n",
    "\n",
    "# Create weights path if does not exist already\n",
    "if not os.path.exists(f'weights/{model_name_save}'):\n",
    "    os.mkdir(f'weights/{model_name_save}')\n",
    "\n",
    "print(f'Model name: {model_name_save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = make_submission(test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = f'submissions/{model_name_save}_submission.csv'\n",
    "submission.to_csv(submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
